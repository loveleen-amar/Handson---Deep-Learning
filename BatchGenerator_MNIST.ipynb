{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17100041_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lw-XmJpKUOH",
        "colab_type": "text"
      },
      "source": [
        "# ***Instantiating a small convnet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pezy6gA1J-VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ggHY-k3Kf6S",
        "colab_type": "text"
      },
      "source": [
        "A convnet takes as input tensors of shape **(image_height, image_width, image_channels)** (not including the batch dimension)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bfus1DBLxcE",
        "colab_type": "text"
      },
      "source": [
        "In this case, we’ll configure the convnet to process inputs of size (28, 28, 1), which is the format of MNIST images. \n",
        "\n",
        "We’ll do this by passing the argument input_shape=(28, 28, 1) to the first layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsng3Ge2LmN0",
        "colab_type": "text"
      },
      "source": [
        "**Let’s display the architecture of the convnet so far:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBHFQVrRKxgg",
        "colab_type": "code",
        "outputId": "0250a73b-7df1-4415-9120-7ca3ac470452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDhaf5zQLNKH",
        "colab_type": "text"
      },
      "source": [
        "You can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). \n",
        "\n",
        "The width and height dimensions tend to shrink as you go deeper in the network. \n",
        "\n",
        "The number of channels is controlled by the first argument passed to the Conv2D layers (32 or 64)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgLwlwlmLb3q",
        "colab_type": "text"
      },
      "source": [
        "The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you’re already familiar with: a stack of Dense layers. \n",
        "\n",
        "These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAwU4e3rO16Z",
        "colab_type": "text"
      },
      "source": [
        "# **Adding a classifier on top of the convnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmXMsq3ELgQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzaD6U3aTEAf",
        "colab_type": "text"
      },
      "source": [
        "We’ll do 10-way classification, using a final layer with 10 outputs and a softmax activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoQvFdAbTH34",
        "colab_type": "text"
      },
      "source": [
        "Here’s what the network looks like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfmEPma6S_GL",
        "colab_type": "code",
        "outputId": "4eb8849e-1a0d-422a-b188-a941ebd4fd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyvxNbwbTSe3",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the (3, 3, 64) outputs are flattened into vectors of shape (576,) before going through two Dense layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgpwaOI4TWLX",
        "colab_type": "text"
      },
      "source": [
        "Now, let’s train the convnet on the MNIST digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lq3lF0FTbxU",
        "colab_type": "text"
      },
      "source": [
        "# **Training the convnet on MNIST images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLMYDFsBTZlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjVbV29jF1ZA",
        "colab_type": "code",
        "outputId": "346b2402-46b9-49b1-a42a-bce85ca7b53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROP9vW3JFiml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLe82aRcFv23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCw-hjSnToq_",
        "colab_type": "code",
        "outputId": "d2389cfd-7adc-4886-e17b-7f372ce73345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=3, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.2464 - acc: 0.9233\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0534 - acc: 0.9836\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0357 - acc: 0.9888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5fb052b978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2RasWxQTvf_",
        "colab_type": "code",
        "outputId": "ad7a049f-2fb7-4bfa-8f49-8348260462e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "test_acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfZwm5wTyuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lagS6ESPJdzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        horizontal_flip=False, \n",
        "        vertical_flip=False)  \n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G2KRRl5J3Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=512\n",
        "epochs=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZI9Ax3jJk0A",
        "colab_type": "code",
        "outputId": "62fa4223-0b71-430c-e38f-af76a15f87d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "history = model.fit_generator(datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (test_images, test_labels), steps_per_epoch=train_images.shape[0] // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 2s 16ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0251 - val_acc: 0.9927\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 2s 16ms/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0269 - val_acc: 0.9922\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0298 - val_acc: 0.9928\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0246 - val_acc: 0.9933\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 2s 16ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0313 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEWlwLK6KQYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7AqVmBgK52x",
        "colab_type": "code",
        "outputId": "546a00b1-8084-47f6-bb87-984ef588acc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "ind = np.random.randint(len(test_images))\n",
        "pred = model.predict(np.expand_dims(test_images[ind],0))\n",
        "plt.imshow((test_images[ind].squeeze()*255).astype(np.uint8),cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Predicted {}'.format(np.argmax(pred,axis=1)[0]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_nNo3TANz1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}